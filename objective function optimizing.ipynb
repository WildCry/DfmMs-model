{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FetchFred:\n",
    "    def __init__(self) -> None:\n",
    "        self.key = Fred(api_key='d59606a150e09c54fd5158bac863da0d') # Jeg skuler min nøkkel her. Skaff din egen.\n",
    "        \n",
    "    def fetch(self, series: dict = {\n",
    "    # name : series id\n",
    "    'MTS' : 'CMRMTSPL', # manufacturing and trade sales\n",
    "    'PILTP' : 'W875RX1', # total personal income less transfer payments\n",
    "    'ENAP' : 'PAYEMS', # employees on nonagricultural payrolls\n",
    "    'IPMAN' : 'IPMAN' # industrial production\n",
    "    }) -> pd.DataFrame:\n",
    "        \n",
    "        \n",
    "        lst = []\n",
    "        for i in series.keys():\n",
    "            data = self.key.get_series(series[i])\n",
    "            data = data.rename(i)\n",
    "            lst.append(data)\n",
    "        return pd.concat(lst, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from fredapi import Fred\n",
    "import pandas as pd\n",
    "\n",
    "class FetchFred:\n",
    "    \"\"\"\n",
    "    Class to fetch data series from the FRED (Federal Reserve Economic Data) API.\n",
    "    \"\"\"\n",
    "    def __init__(self, api_key=None) -> None:\n",
    "        \"\"\"\n",
    "        Initializes the FetchFred object with an API key.\n",
    "        :param api_key: FRED API key. If None, tries to get from environment variable FRED_API_KEY.\n",
    "        \"\"\"\n",
    "        self.key = Fred(api_key='d59606a150e09c54fd5158bac863da0d')\n",
    "\n",
    "    def fetch(self, series=None) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Fetches the specified data series from FRED and returns them as a pandas DataFrame.\n",
    "        :param series: Dictionary mapping series names to FRED series IDs. Uses a default if None.\n",
    "        :return: DataFrame with each series as a column.\n",
    "        \"\"\"\n",
    "        \n",
    "        if series is None:\n",
    "            series = {'MTS': 'CMRMTSPL', 'PILTP': 'W875RX1', 'ENAP': 'PAYEMS', 'IPMAN': 'IPMAN'}\n",
    "        try:\n",
    "            lst = [self.key.get_series(series_id).rename(series_name) for series_name, series_id in series.items()]\n",
    "            return pd.concat(lst, axis=1)\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to fetch data: {e}\")\n",
    "            return pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from fredapi import Fred\n",
    "import pickle\n",
    "import datetime\n",
    "\n",
    "class FetchFred:\n",
    "    \"\"\"\n",
    "    Class to fetch data series from the FRED (Federal Reserve Economic Data) API with caching.\n",
    "    \"\"\"\n",
    "    def __init__(self, api_key=None, cache_dir: str ='fred_cache') -> None:\n",
    "        \"\"\"\n",
    "        Initializes the FetchFred object with an API key and cache directory.\n",
    "        :param api_key: FRED API key. If None, tries to get from environment variable FRED_API_KEY.\n",
    "        :param cache_dir: Directory to store cached data.\n",
    "        \"\"\"\n",
    "        self.key = Fred(api_key if api_key is not None else os.getenv('FRED_API_KEY'))\n",
    "        self.cache_dir = cache_dir\n",
    "        if not os.path.exists(cache_dir):\n",
    "            os.makedirs(cache_dir)\n",
    "    \n",
    "    def _get_cache_path(self, series_id):\n",
    "        \"\"\"\n",
    "        Constructs a file path for a given series ID.\n",
    "        \"\"\"\n",
    "        return os.path.join(self.cache_dir, f\"{series_id}.pkl\")\n",
    "\n",
    "    def _is_cache_valid(self, cache_path, max_age_days=1):\n",
    "        \"\"\"\n",
    "        Checks if the cache file exists and is not too old.\n",
    "        \"\"\"\n",
    "        if os.path.exists(cache_path):\n",
    "            mod_time = os.path.getmtime(cache_path)\n",
    "            current_time = datetime.datetime.now().timestamp()\n",
    "            return (current_time - mod_time) / 3600 / 24 <= max_age_days\n",
    "        return False\n",
    "\n",
    "    def fetch(self, series=None, max_age_days=1) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Fetches the specified data series from FRED, either from the cache or the API, and returns them as a pandas DataFrame.\n",
    "        :param series: Dictionary mapping series names to FRED series IDs. Uses a default if None.\n",
    "        :param max_age_days: Maximum age of the cache in days before it's considered expired.\n",
    "        :return: DataFrame with each series as a column.\n",
    "        \"\"\"\n",
    "        if series is None:\n",
    "            series = {'MTS': 'CMRMTSPL', 'PILTP': 'W875RX1', 'ENAP': 'PAYEMS', 'IPMAN': 'IPMAN'}\n",
    "        \n",
    "        lst = []\n",
    "        for series_name, series_id in series.items():\n",
    "            cache_path = self._get_cache_path(series_id)\n",
    "            if self._is_cache_valid(cache_path, max_age_days):\n",
    "                with open(cache_path, 'rb') as f:\n",
    "                    series_data = pickle.load(f)\n",
    "            else:\n",
    "                try:\n",
    "                    series_data = self.key.get_series(series_id)\n",
    "                    with open(cache_path, 'wb') as f:\n",
    "                        pickle.dump(series_data, f)\n",
    "                except Exception as e:\n",
    "                    print(f\"Failed to fetch data for {series_name}: {e}\")\n",
    "                    continue\n",
    "            lst.append(series_data.rename(series_name))\n",
    "        return pd.concat(lst, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from fredapi import Fred\n",
    "import pickle\n",
    "import datetime\n",
    "\n",
    "class FetchFred:\n",
    "    def __init__(self, api_key=None, cache_dir='fred_cache') -> None:\n",
    "        self.key = Fred(api_key if api_key is not None else os.getenv('FRED_API_KEY'))\n",
    "        self.cache_dir = cache_dir\n",
    "        if not os.path.exists(cache_dir):\n",
    "            os.makedirs(cache_dir)\n",
    "\n",
    "    def _get_cache_path(self, series_id):\n",
    "        return os.path.join(self.cache_dir, f\"{series_id}.pkl\")\n",
    "\n",
    "    def _is_cache_valid(self, cache_path, max_age_days=1):\n",
    "        if os.path.exists(cache_path):\n",
    "            mod_time = os.path.getmtime(cache_path)\n",
    "            current_time = datetime.datetime.now().timestamp()\n",
    "            return (current_time - mod_time) / 3600 / 24 <= max_age_days\n",
    "        return False\n",
    "\n",
    "    def list_cached_series(self):\n",
    "        \"\"\"\n",
    "        Lists all series IDs that are currently cached.\n",
    "        \"\"\"\n",
    "        cached_files = os.listdir(self.cache_dir)\n",
    "        series_ids = [os.path.splitext(file)[0] for file in cached_files]\n",
    "        return series_ids\n",
    "\n",
    "    def check_series_cache_status(self, series_ids, max_age_days=1):\n",
    "        \"\"\"\n",
    "        Checks and reports the cache status of a given series or a list of series.\n",
    "        :param series_ids: A list of series IDs to check.\n",
    "        :param max_age_days: Maximum age of the cache in days before it's considered expired.\n",
    "        :return: A dictionary with series IDs as keys and cache status ('Cached', 'Valid', 'Expired', 'Not Cached') as values.\n",
    "        \"\"\"\n",
    "        status = {}\n",
    "        for series_id in series_ids:\n",
    "            cache_path = self._get_cache_path(series_id)\n",
    "            if os.path.exists(cache_path):\n",
    "                if self._is_cache_valid(cache_path, max_age_days):\n",
    "                    status[series_id] = 'Valid'\n",
    "                else:\n",
    "                    status[series_id] = 'Expired'\n",
    "            else:\n",
    "                status[series_id] = 'Not Cached'\n",
    "        return status\n",
    "\n",
    "    def fetch(self, series=None, max_age_days=1) -> pd.DataFrame:\n",
    "        if series is None:\n",
    "            series = {'MTS': 'CMRMTSPL', 'PILTP': 'W875RX1', 'ENAP': 'PAYEMS', 'IPMAN': 'IPMAN'}\n",
    "        \n",
    "        lst = []\n",
    "        for series_name, series_id in series.items():\n",
    "            cache_path = self._get_cache_path(series_id)\n",
    "            if self._is_cache_valid(cache_path, max_age_days):\n",
    "                with open(cache_path, 'rb') as f:\n",
    "                    series_data = pickle.load(f)\n",
    "            else:\n",
    "                try:\n",
    "                    series_data = self.key.get_series(series_id)\n",
    "                    with open(cache_path, 'wb') as f:\n",
    "                        pickle.dump(series_data, f)\n",
    "                except Exception as e:\n",
    "                    print(f\"Failed to fetch data for {series_name}: {e}\")\n",
    "                    continue\n",
    "            lst.append(series_data.rename(series_name))\n",
    "        return pd.concat(lst, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(os.getenv('FRED_API_KEY'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "fred=FetchFred(api_key='d59606a150e09c54fd5158bac863da0d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GDP</th>\n",
       "      <th>MTS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1946-01-01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1946-04-01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1946-07-01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1946-10-01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1947-01-01</th>\n",
       "      <td>243.164</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1497717.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-09-01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1507530.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-10-01</th>\n",
       "      <td>27944.627</td>\n",
       "      <td>1505477.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-11-01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1514733.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1530296.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  GDP        MTS\n",
       "1946-01-01        NaN        NaN\n",
       "1946-04-01        NaN        NaN\n",
       "1946-07-01        NaN        NaN\n",
       "1946-10-01        NaN        NaN\n",
       "1947-01-01    243.164        NaN\n",
       "...               ...        ...\n",
       "2023-08-01        NaN  1497717.0\n",
       "2023-09-01        NaN  1507530.0\n",
       "2023-10-01  27944.627  1505477.0\n",
       "2023-11-01        NaN  1514733.0\n",
       "2023-12-01        NaN  1530296.0\n",
       "\n",
       "[768 rows x 2 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fred.fetch(series={'GDP' : 'GDP', 'MTS': 'CMRMTSPL'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import fredkey\n",
    "fred = Fred(api_key='d59606a150e09c54fd5158bac863da0d') # Jeg skuler min nøkkel her. Skaff din egen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# requesting data used in the Chauvet paper\n",
    "series = {\n",
    "   # name : series id\n",
    "    'MTS' : 'CMRMTSPL', # manufacturing and trade sales\n",
    "    'PILTP' : 'W875RX1', # total personal income less transfer payments\n",
    "    'ENAP' : 'PAYEMS', # employees on nonagricultural payrolls\n",
    "    'IPMAN' : 'IPMAN' # industrial production\n",
    "}\n",
    "\n",
    "def gen_dataset(series: dict):\n",
    "    lst = []\n",
    "    for i in series.keys():\n",
    "        data = fred.get_series(series[i])\n",
    "        data = data.rename(i)\n",
    "        lst.append(data)\n",
    "    \n",
    "    return pd.concat(lst, axis=1)\n",
    "\n",
    "raw = gen_dataset(series)\n",
    "raw = raw.dropna()\n",
    "\n",
    "\n",
    "# preprocessing\n",
    "df = raw.apply(lambda x: np.log(x))\n",
    "df = df.diff()\n",
    "df = df.dropna()\n",
    "\n",
    "scaler = StandardScaler()\n",
    "df = pd.DataFrame(scaler.fit_transform(df), columns = df.columns, index = df.index)\n",
    "\n",
    "# print"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jobb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
